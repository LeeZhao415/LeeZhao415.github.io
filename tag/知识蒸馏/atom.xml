<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://leezhao415.github.io</id>
    <title>且听风吟，御剑于心！ • Posts by &#34;知识蒸馏&#34; tag</title>
    <link href="https://leezhao415.github.io" />
    <updated>2021-12-12T10:23:56.000Z</updated>
    <category term="人工智能/CV" />
    <category term="Transformer/DETR(CV)" />
    <category term="人工智能" />
    <category term="数据集" />
    <category term="大数据框架" />
    <category term="编程工具" />
    <category term="NLP" />
    <category term="模型部署" />
    <category term="数据结构与算法" />
    <category term="Python数据分析" />
    <category term="网络通信" />
    <category term="YOLOX" />
    <category term="CV算法" />
    <category term="VSLAM" />
    <category term="NCNN部署" />
    <category term="YOLOX目标检测" />
    <category term="多模态" />
    <category term="目标检测（人脸检测）" />
    <category term="目标跟踪" />
    <category term="深度学习" />
    <category term="CV未来" />
    <category term="且读文摘" />
    <category term="NLP-BERT" />
    <category term="自然语言处理NLP" />
    <category term="IOU" />
    <category term="OpenCV之DNN模块" />
    <category term="深度模型" />
    <category term="激活函数" />
    <category term="NLP-模型优化" />
    <category term="梯度更新" />
    <category term="概述" />
    <category term="人脸识别" />
    <category term="名人名言" />
    <category term="寒窑赋" />
    <category term="NLP/评估指标" />
    <category term="度量学习" />
    <category term="智能家居" />
    <category term="机器学习/损失函数" />
    <category term="机器学习" />
    <category term="CV/目标检测工具箱" />
    <category term="模型性能指标" />
    <category term="科研项目成果" />
    <category term="计算机顶会" />
    <category term="表面缺陷检测" />
    <category term="计算机视觉CV" />
    <category term="网络编程" />
    <category term="NLP/数据增强工具" />
    <category term="AIGC前沿" />
    <category term="计算机视觉" />
    <category term="模型优化" />
    <category term="三维建模" />
    <category term="计算机视觉库" />
    <category term="深度学习环境配置" />
    <category term="知识蒸馏" />
    <category term="多任务学习模型" />
    <category term="数据库原理" />
    <category term="算法" />
    <category term="操作系统" />
    <category term="深度模型（目标检测）" />
    <category term="视频理解" />
    <category term="ReID" />
    <category term="MOT" />
    <category term="NLP-发展史" />
    <category term="编程语言" />
    <category term="CV数据集" />
    <category term="Linux" />
    <category term="PaddlePaddle" />
    <entry>
        <id>https://leezhao415.github.io/2021/12/12/%E5%9F%BA%E4%BA%8E-Multiple-Teacher-Single-Student-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%A4%9A%E9%A2%86%E5%9F%9F%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B/</id>
        <title>基于 Multiple Teacher Single Student 框架的多领域对话模型</title>
        <link rel="alternate" href="https://leezhao415.github.io/2021/12/12/%E5%9F%BA%E4%BA%8E-Multiple-Teacher-Single-Student-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%A4%9A%E9%A2%86%E5%9F%9F%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B/"/>
        <content type="html">&lt;meta name=&#34;referrer&#34; content=&#34;no-referrer&#34;&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;文章目录&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%A4%9A%E9%A2%86%E5%9F%9F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E4%B8%AD%E6%A3%98%E6%89%8B%E7%9A%84%E7%8A%B6%E6%80%81%E8%A1%A8%E7%A4%BA%E9%97%AE%E9%A2%98&#34;&gt;多领域对话系统中棘手的状态表示问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%9D%A5%E6%BA%90%E4%BA%8E%E7%94%9F%E6%B4%BB%E7%9A%84-mtssmultiple-teachers-single-student%E6%A8%A1%E5%9E%8B&#34;&gt;来源于生活的 MTSS（Multiple Teachers Single Student）模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mtss-%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84&#34;&gt;MTSS 的模型结构&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#model-overview&#34;&gt;Model Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#teacher-model&#34;&gt;Teacher Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#student-model&#34;&gt;Student Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mtss-%E4%B8%AD%E7%9A%84%E7%9F%A5%E8%AF%86%E8%BF%81%E7%A7%BB%E6%96%B9%E6%B3%95&#34;&gt;MTSS 中的知识迁移方法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%96%87%E6%9C%AC%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9F%A5%E8%AF%86%E8%BF%81%E7%A7%BB&#34;&gt;文本级别的知识迁移&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90&#34;&gt;实验与结果分析&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%95%B0%E6%8D%AE%E9%9B%86&#34;&gt;数据集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E5%AE%9A&#34;&gt;实验设定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90&#34;&gt;结果分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%80%BB%E7%BB%93&#34;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%90%8E%E8%AE%B0&#34;&gt;后记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
&lt;hr&gt;
&lt;p&gt;导读：一个源于高考的高性能多领域对话模型。&lt;/p&gt;
&lt;p&gt;作者 | 珂蓝、元淳&lt;br&gt;
来源 | 凌云时刻（微信号：linuxpk）&lt;/p&gt;
&lt;p&gt;朴素的思想：多个师傅教出综合徒弟&lt;/p&gt;
&lt;p&gt;一切都从高考开始谈起。&lt;/p&gt;
&lt;p&gt;每一个高考生在学习语文、数学、外语、物理等学科时，并非是自己抱着一摞各个学科的书籍独自啃读，而是向相应学科的老师进行学习，参加高考时，学得好的学生在高考这种多学科测试中，往往要比单个学科的老师表现出色。毕竟，学生是博采百家之长。&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Db3F4SUY4VHhCZkhpYUxwbDNndUNsU2Q2SWxwM09Jb2pia1lNT2ljOVRreFhBNFhYb2x2UkhGMHpzZGNjMXg2SHRsU2lhcGpQdTFmaWJJRFJpYk16MGdUTU53LzY0MA?x-oss-process=image/format,png&#34; alt=&#34;img&#34; style=&#34;zoom:50%;&#34;&gt;&lt;/center&gt;
&lt;h4&gt;&lt;span id=&#34;多领域对话系统中棘手的状态表示问题&#34;&gt; 多领域对话系统中棘手的状态表示问题&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;在对话处理的过程中，对话状态表示是个至关重要的部分，对话管理模块往往需要精确记录当前对话的状态才能做出正确的对话决策。&lt;/p&gt;
&lt;p&gt;任务型对话系统上有两种常用的对话状态表示方法：&lt;/p&gt;
&lt;p&gt;状态追踪（State Tracking）：基于状态追踪的方式一般采用一个额外的信念状态追踪模块，从原始的用户文本中抽取出必要的对话本体信息，这些本体信息包括实体值、槽位等，用来表示一段特定的对话状态。&lt;/p&gt;
&lt;p&gt;隐向量状态表示：隐向量的状态表示方法则直接将所有的对话历史信息进行压缩，得到用于表示状态的隐向量。&lt;/p&gt;
&lt;p&gt;这两种方法在单个领域的对话任务，诸如机票预订的场景下，有着良好的性能表现。这是由于在单一领域下，所涉及的实体值和槽位数量往往很少。然而，当场景切换到多领域对话时，这两种方法的性能会急剧下降:&lt;/p&gt;
&lt;p&gt;对于状态追踪方法来说，多领域下本体信息空间成倍地增加，从而导致状态追踪模块在实体值和槽位识别上的准确率大幅下降，进而影响了对话系统。&lt;/p&gt;
&lt;p&gt;而对于隐向量的状态表示来说，由于直接使用了隐向量而非人工定义的状态，训练数据中关于实体和槽位的人工标注信息无法被充分利用。除此之外，隐向量的状态不具备可读性，是一个黑盒式的表示，难以针对特定领域的问题进行描述。&lt;/p&gt;
&lt;p&gt;综上，多领域下低质量低精度的状态表示影响了对话系统的对话策略，进一步影响了对话系统的整体表现。&lt;/p&gt;
&lt;h4&gt;&lt;span id=&#34;来源于生活的-mtssmultiple-teachers-single-student模型&#34;&gt; 来源于生活的 MTSS（Multiple Teachers Single Student）模型&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;为了解决上述问题并建立一个高性能的多领域对话模型，我们提出了多教师 — 单学生对话模型 MTSS（Multiple Teachers Single Student）。&lt;/p&gt;
&lt;p&gt;这种模型能分块式地学习多领域下复杂的对话状态表示，最终得到多领域下优异的对话策略。MTSS 模型使用了多个教师模型，每个模型学习一个领域下优秀的对话策略。多个教师模型再将知识和策略教授给一个通用的学生模型，使得学生模型成为所有领域的专家对话模型。这种多教师 - 单学生的场景能很好地解决多领域对话的问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在多领域对话任务下的每一个领域，使用一个独立的教师模型，来学习领域特定的知识，同时也额外学习领域下人工标注的语意信息。每个领域下的教师模型使用用户文本语句和基于人工语意标注的状态表示作为输入，从这些特定领域下的文本和状态中，领域教师模型能学到高质量的对话策略方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这些训练好的、领域特定的教师模型将各自学到的知识和对话策略传递到一个通用的学生模型中，通过基于文本的引导和基于策略的引导两种方式将这些知识信息传递到学生模型，传递的过程则采用知识蒸馏算法来实现。通过从领域特定的教师模型学习，通用学生模型既学到了多领域的知识，同时也学到了额外的语意标注信息，从而有着良好的多领域对话表现。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;span id=&#34;mtss-的模型结构&#34;&gt; MTSS 的模型结构&lt;/span&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;span id=&#34;model-overview&#34;&gt; Model Overview&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;MTSS 的整体框架如图所示（图中仅画出了两个教师模型，实际教师模型的数量取决于多领域对话的领域数量）。&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Db3F4SUY4VHhCZkhpYUxwbDNndUNsU2Q2SWxwM09Jb2pqR3lFdUVOR2F1akpnYjNpYzdGaWJjbndJbFlTaWFOOGliUjh6UUhPU2pxeXlDZFpBMzZEaWF3aWJWY2cvNjQw?x-oss-process=image/format,png&#34; alt=&#34;img&#34; style=&#34;zoom: 67%;&#34;&gt;&lt;/center&gt;
&lt;p&gt;主要由两个部分组成：教师模型和学生模型。&lt;/p&gt;
&lt;p&gt;教师模型通常是由多领域场景下的领域数决定，通常每个领域下建立一个教师模型。&lt;/p&gt;
&lt;p&gt;在训练过程中，教师模型和学生模型所接收的输入是不同的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;教师模型接收当前用户语句和人工标注的状态表示作为输入。由于状态表示由人工标注，因此具有非常高的准确度，从而保证了教师模型从这些语意信息中能获得足够多的正确信息用于对话决策和回复生成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;学生模型仅使用当前用户输入和历史对话作为输入。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在经过充分训练后，教师模型再通过文本引导和策略引导两种方式将知识传递到学生模型。使用文本引导使得学生模型和教师模型生成相似的回复，使用策略引导则使得学生模型学习教师模型的对话策略，从而保证学生模型能充分接收来自教师模型的知识。下一节将详细描述教师和学生之间的交互方式。&lt;/p&gt;
&lt;p&gt;完成上述的训练过程后，学生模型获得了充分的多领域知识以及足够正确的对话策略。在模型测试和部署时，学生模型只需要原始的文本作为输入，不需要额外的语意和状态标注即可生成高质量的回复。&lt;/p&gt;
&lt;h5&gt;&lt;span id=&#34;teacher-model&#34;&gt; Teacher Model&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;我们采用了 Budzianowski 提出的对话模型作为教师模型。如下图所示，&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Db3F4SUY4VHhCZkhpYUxwbDNndUNsU2Q2SWxwM09Jb2pPQ1FzbkxqVDVzQm5NWjBiZWliemliSzBic216TFUzOU9qeGc1MDRvS3ZSNmhaMk42SlVjY3dSUS82NDA?x-oss-process=image/format,png&#34; alt=&#34;img&#34; style=&#34;zoom: 25%;&#34;&gt;&lt;/center&gt;
&lt;p&gt;教师模型由三部分构成：编码器，解码器以及中间的策略模型。策略模型同时使用了来自编码器的句表示向量 utut 和来自人工定义的特征向量 etet 作为输入。特征向量又由两个部分组成，第一部分是置信状态向量 vbvb，置信状态向量的每一个维度均使用了独热（one-hot）编码，映射到领域下某个特定的槽位，槽位中的实体值需要由用户给出。当某个值在对话中已经被给定，则当前位置的编码设定为 1，否则设定为 0。因此，置信状态向量 vbvb 代表在当前对话状态下，系统所记录的必要信息。在对话每一轮，置信状态都会根据语意标注信息进行更新。特征的另一部分是数据库指示向量 vkbvkb。数据库指示向量表示满足用户需求的实体在数据库中的个数。使用 4 维的独热编码来记录这个数值，每一维分别表示数量为 0，1，2 或者大于等于 3 个候选实体。并将将以上 3 个向量 —— 句向量 vutvtu，置信状态向量 vbvb 和数据库指示向量 vkbvkb—— 拼接到一起，就得到了当前对话完整的状态表示 stst。&lt;/p&gt;
&lt;p&gt;得到拼接向量后，将拼接向量输入策略层，策略层由一层的次线性全连接构成，使用 tanhtanh 作为激活函数，并由策略层得到决策向量 atat：&lt;/p&gt;
&lt;p&gt;at=tanh(w⋅[vut;vb;vkb]),at=tanh(w⋅[vtu;vb;vkb]),&lt;/p&gt;
&lt;p&gt;其中 [;][;] 表示拼接操作。决策向量 atat 最终被输入解码器模块，解码器由输入的决策向量和注意力机制增强来产生最终的输出。由于每个教师模型各自独立，因此每个教师模型所学习的状态信息是各不相同的。在教师模型经过充分预训练后，将教师模型作为引导模型来训练学生模型。&lt;/p&gt;
&lt;p&gt;教师模型的训练过程中直接使用真值回复数据作为训练模板。对于教师模型，给定用户输入 uu 和状态表示 ss，模型旨在优化真实回复 r={wr0,wr1,…,wrm} r={w0r,w1r,…,wmr}。和生成回复&lt;sup&gt; rr&lt;/sup&gt; 之间的负对数似然损失：&lt;/p&gt;
&lt;p&gt;JNLL(&lt;sup&gt;r|u,s)=−m∑i=0∑&lt;/sup&gt;wi∈V1}logp(&lt;sup&gt;wi|u,s,wr0∼i−1;ϕ),JNLL(r&lt;/sup&gt;|u,s)=−∑i=0m∑w&lt;sup&gt;i∈V1{w^i=wir}log⁡p(w&lt;/sup&gt;i|u,s,w0∼i−1r;ϕ),&lt;/p&gt;
&lt;p&gt;其中 VV 表示生成词构成的词表， ϕϕ 表示教师模型的参数，1 {⋅} 1 {⋅} 表示指示函数（当括号内表达式成立时值为 1，否则为 0）。&lt;/p&gt;
&lt;h5&gt;&lt;span id=&#34;student-model&#34;&gt; Student Model&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;学生模型，也是通用多领域的对话模型，是 MTSS 框架最终产出的模型。通用学生模型不使用额外的状态信息作为输入，它本身应当具有建模完整对话上下文的能力。基于此，我们选用 HRED 模型作为通用学生模型的基本框架。&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Db3F4SUY4VHhCZkhpYUxwbDNndUNsU2Q2SWxwM09Jb2pObFE4TERDRDBQbWVwS21kQ3BXNWNrSHdFMHdKTzdXZmNnaWJ0S2MyekNmcnlHN1BWaWFVRWVpY1EvNjQw?x-oss-process=image/format,png&#34; alt=&#34;img&#34; style=&#34;zoom: 25%;&#34;&gt;&lt;/center&gt;
&lt;p&gt;如图，首先使用一个编码器来建模当前用户的输入语句，并将其编码为一个句向量表示。HRED 中所有对话历史的句向量又由一个上下文编码器编码得到上下文向量。在 tt 时刻，对于包含 mm 个词 (w0,w1,…,wm)(w0,w1,…,wm) 的输入语句 utut，使用 LSTM 作为编码器编码：&lt;/p&gt;
&lt;p&gt;ht=vwtm=LSTMe(h0;wt0,wt1,…wtm),ht=vtmw=LSTMe(h0;wt0,wt1,…wtm),&lt;/p&gt;
&lt;p&gt;然后将 LSTM 的隐状态视为句向量表示 vut=htvtu=ht。而上下文编码器则同时作为策略模块，根据所有的历史语句得到决策向量 aat。同样使用 LSTM 作为上下文编码器实现：&lt;/p&gt;
&lt;p&gt;at=LSTMc(vu0,vu1,…,vut),at=LSTMc(v0u,v1u,…,vtu),&lt;/p&gt;
&lt;p&gt;其中 atat 作为抽象的决策向量，用于表示对当前回复的决策。通过这种将上下文编码向量视为决策向量的方式以及使用教师 — 学生框架的策略层引导方法，能有效提升学生模型的表现。&lt;/p&gt;
&lt;p&gt;在模型的最后，我们使用 NLG 模型生成自然语言回复 rtrt，上一层的决策向量作为 NLG 模块 LSTM 模型的初始状&lt;/p&gt;
&lt;p&gt;vri=LSTMd(at,vw0∼m,vr0∼i−1),vir=LSTMd(at,v0∼mw,v0∼i−1r),&lt;/p&gt;
&lt;p&gt;其中 vwjvjw 是编码器对第 jj 个输入词的编码向量。&lt;/p&gt;
&lt;p&gt;与教师模型相同，学生模型同样学习真值回复数据。但在训练过程中，学生模型的输入数据有所不同，没有额外的状态表示作为输入，学生模型需要从文本中总结隐状态信息。此外，学生模型同时学习教师模型的指导信息。&lt;/p&gt;
&lt;h4&gt;&lt;span id=&#34;mtss-中的知识迁移方法&#34;&gt; MTSS 中的知识迁移方法&lt;/span&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;span id=&#34;文本级别的知识迁移&#34;&gt; 文本级别的知识迁移&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;知识迁移过程旨在让学生模型学习与教师模型相似的回复输出。在每个时间步骤学生模型的生成词概率需要分别与教师模型一致。为实现这一点，我们使用交叉熵损失来衡量学生和教师之间词概率的相似度。损失的表达式是：&lt;/p&gt;
&lt;p&gt;JKD=−m∑i=0∑wri∈Vp(wri|u,s,wr0∼i−1;ϕ)logp(wri|u,c,wr0∼i−1;θ),JKD=−∑i=0m∑wir∈Vp(wir|u,s,w0∼i−1r;ϕ)log⁡p(wir|u,c,w0∼i−1r;θ),&lt;/p&gt;
&lt;p&gt;其中 ϕϕ 为教师模型的参数，θθ 为学生模型的参数，VV 为生成词表。基于真值回复的训练在每个生成位置仅学习了一个独热的词的概率，而对于文本级别的蒸馏方法，来自教师模型的输出提供的一个更加平滑全词概率分布，这种基于概率的蒸馏方法可使得学生模型的生成更加自然，正确率更高。&lt;/p&gt;
&lt;p&gt;策略级别的知识引导方法&lt;br&gt;
策略级别的知识引导旨在让学生模型学到教师模型的对话策略。即在相同的输入下，学生模型和教师模型能做出相同的对话决策。将教师模型的中间层输出，表示决策的向量 aTaT 同样视为目标数据，由学生模型来学习。对于同样作为隐向量的 aTaT 和 aSaS，在训练过程中使用均方误差（Mean Squared Error, MSE）来作为训练的损失从而让学生学习教师的决策：&lt;/p&gt;
&lt;p&gt;JKD−π=1kk∑i=0(aTi−aSi)2.JKD−π=1k∑i=0k(aiT−aiS)2.&lt;/p&gt;
&lt;p&gt;我们同时使用了真值（ground truth）回复和教师模型的引导来作为训练目标。将文本蒸馏和策略蒸馏产生的两种损失加到真值训练损失当中。为了调整教师模型引导的影响力和不同损失之间的权重，使用了两个权重张量，α1α1 作为文本蒸馏损失的权值，α2α2 作为策略蒸馏的权值，最终得到用于训练学生模型的联合损失 JθJθ 可以表示为：&lt;/p&gt;
&lt;p&gt;Jθ=JNLL+α1JKD+α2JKD−π,Jθ=JNLL+α1JKD+α2JKD−π,&lt;/p&gt;
&lt;p&gt;然后通过最小化这个损失值来训练学生模型，实现教师对学生的引导。&lt;/p&gt;
&lt;h4&gt;&lt;span id=&#34;实验与结果分析&#34;&gt; 实验与结果分析&lt;/span&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;span id=&#34;数据集&#34;&gt; 数据集&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;在实验数据上，我们选择了 MultiWOZ 多领域任务对话数据集作为对话数据集和模型效果测试数据。MultiWOZ 多领域数据集共包含了 7 个对话领域，分别是：饭店预订，酒店预订，景点查询，出租车预约，火车票预订，医院信息查询和警察局信息查询。MultiWOZ 对话数据集的目的在于获取用户意图，并根据用户意图提供满足用户需求的实体相关的信息。MultiWOZ 数据集中每段对话包含大约 14 个用户与系统之间的对话轮次。部分对话段落的话题仅仅只包含一个领域相关的信息，但更多的对话中，一段对话会包含 2 到 5 个领域的任务，用户会在不同领域之间切换。每个领域下，系统需要从用户中获取大致 4 个左右不同实体的实体值，同时需要向用户提供约 3 个相关实体信息。例如，饭店预订领域，用户需要提供想要预订饭店的地区，价格范围，菜种 3 个信息，系统则需返回用户相关饭店的地址，电话，预约号以及其他一些必要信息。&lt;/p&gt;
&lt;p&gt;为了成功训练模型，我们先对数据进行了预处理。首先进行了去词化（Delexicalization）操作，将所有对话语句中实体的具体实体值替换为占位符，然后根据事先定义的置信状态设计，对每一轮对话根据人工标注的语意信息生成置信状态向量和数据库指示向量。并将这些向量作为教师模型的额外输入。然后对每一轮对话进行领域标注，并根据标注将对话划分到 7 个领域下。领域标注的依据是按照每轮对话中所出现的实体值所属于的领域。对于某些对话来说，无法将这些对话划分到以上 7 个领域的其中一个，例如对话开始的问候和对话结束的招呼语句。为此定义一个通用领域，所有不属于以上 7 个领域的对话轮次被划分到这个通用领域下，从而最终得到 8 个领域的训练数据集，数据集大小如表所示。&lt;/p&gt;
&lt;h5&gt;&lt;span id=&#34;实验设定&#34;&gt; 实验设定&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;在数据集上，我们构建了两个不同的词表，输入词表和输出词表。对于输入词表，筛选去掉了词频小于 5 的所有的词。最终剩余的输入词表大小约为 1300 左右。对于输出词表，按词频排序后直接筛选保留了词频最高的 500 个词。对于输入和输出词表采用了两套不同的词向量。两种词向量的维度均设置为 50。对于其中所有涉及的 LSTM 模型，隐层维度均设计为 150 维。对每个教师模型，首先在训练集上训练，然后选择验证集上指标最好的训练结果作为引导模型。对于学生模型，选择 Adam 优化器，学习率为 0.005，对于用于平衡不同损失的权重值 α1α1 和 α2α2，值均设为 0.005。为了得到稳定的结果。所有模型均经过 3 次或 5 次的重复实验并取了平均值。&lt;/p&gt;
&lt;p&gt;在教师模型的训练中发现，部分领域的训练数据量有限。例如，警察局领域的数据量在整个训练数据中仅占 0.82%，最终在该领域下训练的模型效果较差。为了解决这个问题，我们使用了一种暖启动策略：首先基于所有领域下的数据集，训练一个通用预训练模型 TallTall 作为起点。然后，每个领域下特定的教师模型使用 TallTall 在领域上进行微调训练。这种暖启动的策略能保证每个领域特定的教师模型其性能不弱于或明显强于 TallTall。&lt;/p&gt;
&lt;p&gt;我们选取了以下评价指标来评价每个模型生成的回复。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;BLEU：我们首先使用了 BLEU4 得分作为评价指标，用于评价生成回复与真实回复之间的相似度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inform 指标和 Success 指标：这两种评价指标是由 Budzianowski 提出，作为 MultiWOZ 数据集在对话文本生成的任务上所用的一种评价指标。这两种指标均是从段级别对对话进行评测。其中，Inform 率反映在一整段对话中，系统是否推荐给用户一个符合用户需求的实体信息。Success 率衡量整段对话是否成功，包括是否 Inform 成功，以及用户需要的所有信息是否由系统提供给到了用户。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;&lt;span id=&#34;结果分析&#34;&gt; 结果分析&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;下表表示我们的模型和其他基准模型在多领域场景下的结果表现。&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9Db3F4SUY4VHhCY2xDRjNhVmpjQ09WbERjSE9WdVBVRU9aTHAwRWt4eGQwMnRpYjZleEJScUt5c1RvaWEwbjBxOU9QVnBZUDkzZU1VS0JFZWQ0WDN3dk93LzY0MA?x-oss-process=image/format,png&#34; alt=&#34;img&#34; style=&#34;zoom: 80%;&#34;&gt;&lt;/center&gt;
&lt;p&gt;从表中可以看出，与基准模型诸如 Seq2Seq 和 HRED 模型相比，本文的模型结果优于这些基准方法。通过加入教师 - 学生框架，本文所使用的 HRED 模型相比普通的 HRED 模型，在 Inform 和 Success 两项指标上相比分别提升了 6.8% 和 4.0%。与当前最好的模型，LaRL 和 HDSA 两种对话生成模型，以及当前最好的状态追踪模型 TRADE 的组合相比，模型能达到与之相近的结果表现。然而，这两种最新的对话生成模型相比于我们的模型有以下不足：&lt;/p&gt;
&lt;p&gt;・HDSA 模型使用了 BERT 这个语言模型作为组成的一部分。然而，BERT 虽然能很好地提升模型性能的表现，但同时，也使得模型的体积十分臃肿，在部署到线上使用时会有严重的延迟。&lt;/p&gt;
&lt;p&gt;・LaRL 使用了强化学习的方法，用来优化段级别的最优回馈值，如 Inform 指标或 Success 指标，从而在这种被优化的指标上取得较好的表现，而在未优化的指标诸如 BLEU 上则表现很差。&lt;/p&gt;
&lt;p&gt;此外，在与使用人工状态标记的设定场景下，我们模型与理想化的 Seq2Seq 或者 HRED 模型相比能取得相近或者更高的效果。结果同样表明，一个额外的状态追踪模块对于 Inform 指标有所帮助，而对 Success 指标毫无帮助。&lt;/p&gt;
&lt;h4&gt;&lt;span id=&#34;总结&#34;&gt; 总结&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;我们基于教师学生框架，提出了一种新颖的用于构建高质量多领域对话模型的方法 MTSS。通过构建多个特定领域的教师模型，分块学习多领域下复杂的状态知识，帮助一个通用的学生模型训练，使之成多领域对话专家。为了充分利用领域教师所学到的知识，我们创造性地使用了文本层次的引导和策略层次的引导，来将教师模型的知识传授给学生。&lt;/p&gt;
&lt;p&gt;与此同时，我们的方法存在可以进一步完善的地方。例如，目前在 MTSS 框架中所使用的模型为最基础的 Seq2Seq 模型和 HRED 模型。作为顶层框架，MTSS 有足够的潜力应用到更加新型的对话模型上来。&lt;/p&gt;
&lt;h4&gt;&lt;span id=&#34;后记&#34;&gt; 后记&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;多领域对话系统在我们的业务场景中扮演着越来越重要的地位，举个例子，如果准备出境游：订机票、订景点、订酒店是相辅相成 (【机票到达时间】影响了【酒店位置和入住时间】的选择，同时【酒店】又会进一步影响【当地景点的选择】)。今后我们的智能服务形式更多的是这种多领域交织的形式。我们的 MTSS 模型无疑为多领域对话提供了一种解决方案：博采百家之长，服务综合领域。&lt;/p&gt;
&lt;p&gt;————————————————&lt;br&gt;
 版权声明：本文为 CSDN 博主「凌云时刻」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。&lt;br&gt;
原文链接：&lt;a href=&#34;https://blog.csdn.net/bjchenxu/article/details/109006931&#34;&gt;https://blog.csdn.net/bjchenxu/article/details/109006931&lt;/a&gt;&lt;/p&gt;
</content>
        <category term="人工智能" />
        <category term="知识蒸馏" />
        <updated>2021-12-12T10:23:56.000Z</updated>
    </entry>
</feed>
