<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>NLP之常用预训练模型详解 | 且听风吟，御剑于心！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="LeeZhao,LeeZhao's Blog" />
  
  <meta name="description" content="文章目录   NLP 中流行的预训练模型  1 BERT 及其变体 2 GPT 3 GPT-2 及其变体 4 Transformer-XL 5 XLNet 及其变体 6 XLM 7 RoBERTa 及其变体 8 DistilBERT 及其变体 9 ALBERT 10 T5 及其变体 11 XLM-RoBERTa 及其变体       NLP 中流行的预训练模型  BERT GPT GPT-2">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP之常用预训练模型详解">
<meta property="og:url" content="https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="且听风吟，御剑于心！">
<meta property="og:description" content="文章目录   NLP 中流行的预训练模型  1 BERT 及其变体 2 GPT 3 GPT-2 及其变体 4 Transformer-XL 5 XLNet 及其变体 6 XLM 7 RoBERTa 及其变体 8 DistilBERT 及其变体 9 ALBERT 10 T5 及其变体 11 XLM-RoBERTa 及其变体       NLP 中流行的预训练模型  BERT GPT GPT-2">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-06-24T15:20:07.000Z">
<meta property="article:modified_time" content="2021-06-26T02:41:40.118Z">
<meta property="article:author" content="LeeZhao">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/images/hatRSS blk.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'true', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?true";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>

  
  <div style="display: none;">
    <script src="//s22.cnzz.com/z_stat.php?id=true&web_id=true" language="JavaScript"></script>
  </div>


<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">LeeZhao&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a  href="/about">
                        <i class="fa fa-user"></i>
                        <span>About</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.jpg" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        LeeZhao&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        且听风吟，御剑于心！
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="CSDN" target="_blank" href="//blog.csdn.net/qq_36722887">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="//github.com/leezhao415">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                        <a title="Weibo" target="_blank" href="//weibo.com/u/5120617296/home?topnav=1&wvr=6">
                            <i class="fa fa-weibo fa-2x"></i></a>
                    
                        <a title="CodeSearch" target="_blank" href="//codesearch.aixcoder.com">
                            <i class="fa fa-twitter fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-NLP之常用预训练模型详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      NLP之常用预训练模型详解
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/Hot/">Hot</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2021-06-24
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

          
      </header>
    
    <div class="article-entry post-content" itemprop="articleBody">
      
            
            <meta name="referrer" content="no-referrer">
<hr>
<p><strong>文章目录</strong></p>
<!-- toc -->
<ul>
<li><a href="#nlp%E4%B8%AD%E6%B5%81%E8%A1%8C%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">NLP 中流行的预训练模型</a>
<ul>
<li><a href="#1-bert%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">1 BERT 及其变体</a></li>
<li><a href="#2-gpt">2 GPT</a></li>
<li><a href="#3-gpt-2%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">3 GPT-2 及其变体</a></li>
<li><a href="#4-transformer-xl">4 Transformer-XL</a></li>
<li><a href="#5-xlnet%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">5 XLNet 及其变体</a></li>
<li><a href="#6-xlm">6 XLM</a></li>
<li><a href="#7-roberta%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">7 RoBERTa 及其变体</a></li>
<li><a href="#8-distilbert%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">8 DistilBERT 及其变体</a></li>
<li><a href="#9-albert">9 ALBERT</a></li>
<li><a href="#10-t5%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">10 T5 及其变体</a></li>
<li><a href="#11-xlm-roberta%E5%8F%8A%E5%85%B6%E5%8F%98%E4%BD%93">11 XLM-RoBERTa 及其变体</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<hr>
<h3><span id="nlp-中流行的预训练模型"> NLP 中流行的预训练模型</span></h3>
<ul>
<li>BERT</li>
<li>GPT</li>
<li>GPT-2</li>
<li>Transformer-XL</li>
<li>XLNet</li>
<li>XLM</li>
<li>RoBERTa</li>
<li>DistilBERT</li>
<li>ALBERT</li>
<li>T5</li>
<li>XLM-RoBERTa</li>
</ul>
<hr>
<h4><span id="1-bert-及其变体"> 1 BERT 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">bert-base-uncased</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">小写英文文本</td>
</tr>
<tr>
<td style="text-align:center">bert-large-uncased</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">340M</td>
<td style="text-align:center">小写英文文本</td>
</tr>
<tr>
<td style="text-align:center">bert-base-cased</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">不区分大小写的英文文本</td>
</tr>
<tr>
<td style="text-align:center">bert-large-cased</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">340M</td>
<td style="text-align:center">不区分大小写的英文文本</td>
</tr>
<tr>
<td style="text-align:center">bert-base-multilingual-uncased</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">小写的 102 种语言文本</td>
</tr>
<tr>
<td style="text-align:center">bert-large-multilingual-uncased</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">340M</td>
<td style="text-align:center">小写的 102 种语言文本</td>
</tr>
<tr>
<td style="text-align:center">bert-base-chinese</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">简体和繁体中文文本</td>
</tr>
</tbody>
</table>
<ul>
<li><code>bert-base-uncased</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，在小写的英文文本上进行训练而得到.</li>
<li><code>bert-large-uncased</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 340M 参数量，在小写的英文文本上进行训练而得到.</li>
<li><code>bert-base-cased</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，在不区分大小写的英文文本上进行训练而得到.</li>
<li><code>bert-large-cased</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 340M 参数量，在不区分大小写的英文文本上进行训练而得到.</li>
<li><code>bert-base-multilingual-uncased</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，在小写的 102 种语言文本上进行训练而得到.</li>
<li><code>bert-large-multilingual-uncased</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 340M 参数量，在小写的 102 种语言文本上进行训练而得到.</li>
<li><code>bert-base-chinese</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，在简体和繁体中文文本上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="2-gpt"> 2 GPT</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">openai-gpt</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">英文语料</td>
</tr>
</tbody>
</table>
<ul>
<li><code>openai-gpt</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，由 OpenAI 在英文语料上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="3-gpt-2-及其变体"> 3 GPT-2 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">gpt2</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">117M</td>
<td style="text-align:center">GPT-2 英文语料</td>
</tr>
<tr>
<td style="text-align:center">gpt2-xl</td>
<td style="text-align:center">48</td>
<td style="text-align:center">1600</td>
<td style="text-align:center">25</td>
<td style="text-align:center">1558M</td>
<td style="text-align:center">GPT-2 英文语料</td>
</tr>
</tbody>
</table>
<ul>
<li><code>gpt2</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 117M 参数量，在 OpenAI GPT-2 英文语料上进行训练而得到.</li>
<li><code>gpt2-xl</code> : 编码器具有 48 个隐层，输出 1600 维张量，25 个自注意力头，共 1558M 参数量，在大型的 OpenAI GPT-2 英文语料上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="4-transformer-xl"> 4 Transformer-XL</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">transfo-xl-wt103</td>
<td style="text-align:center">18</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">257M</td>
<td style="text-align:center">wikitext-103 英文语料</td>
</tr>
</tbody>
</table>
<ul>
<li><code>transfo-xl-wt103</code> : 编码器具有 18 个隐层，输出 1024 维张量，16 个自注意力头，共 257M 参数量，在 wikitext-103 英文语料进行训练而得到.</li>
</ul>
<hr>
<h4><span id="5-xlnet-及其变体"> 5 XLNet 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">xlnet-base-cased</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">110M</td>
<td style="text-align:center">英文语料</td>
</tr>
<tr>
<td style="text-align:center">xlnet-large-cased</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">240M</td>
<td style="text-align:center">英文语料</td>
</tr>
</tbody>
</table>
<ul>
<li><code>xlnet-base-cased</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 110M 参数量，在英文语料上进行训练而得到.</li>
<li><code>xlnet-large-cased</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 240 参数量，在英文语料上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="6-xlm"> 6 XLM</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">xlm-mlm-en-2048</td>
<td style="text-align:center">12</td>
<td style="text-align:center">2048</td>
<td style="text-align:center">16</td>
<td style="text-align:center">/</td>
<td style="text-align:center">英文语料</td>
</tr>
</tbody>
</table>
<p><code>xlm-mlm-en-2048</code> : 编码器具有 12 个隐层，输出 2048 维张量，16 个自注意力头，在英文文本上进行训练而得到.</p>
<hr>
<h4><span id="7-roberta-及其变体"> 7 RoBERTa 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">roberta-base</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">125M</td>
<td style="text-align:center">英文文本</td>
</tr>
<tr>
<td style="text-align:center">roberta-large</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">355M</td>
<td style="text-align:center">英文文本</td>
</tr>
</tbody>
</table>
<ul>
<li><code>roberta-base</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 125M 参数量，在英文文本上进行训练而得到.</li>
<li><code>roberta-large</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 355M 参数量，在英文文本上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="8-distilbert-及其变体"> 8 DistilBERT 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">distilbert-base-uncased6</td>
<td style="text-align:center">6</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">66M</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td style="text-align:center">distilbert-base-multilingual-cased</td>
<td style="text-align:center">6</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">66M</td>
<td style="text-align:center">/</td>
</tr>
</tbody>
</table>
<ul>
<li><code>distilbert-base-uncased</code> : 基于 bert-base-uncased 的蒸馏 (压缩) 模型，编码器具有 6 个隐层，输出 768 维张量，12 个自注意力头，共 66M 参数量.</li>
<li><code>distilbert-base-multilingual-cased</code> : 基于 bert-base-multilingual-uncased 的蒸馏 (压缩) 模型，编码器具有 6 个隐层，输出 768 维张量，12 个自注意力头，共 66M 参数量.</li>
</ul>
<hr>
<h4><span id="9-albert"> 9 ALBERT</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">albert-base-v1</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">125M</td>
<td style="text-align:center">英文文本</td>
</tr>
<tr>
<td style="text-align:center">albert-base-v2</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">125M</td>
<td style="text-align:center">英文文本</td>
</tr>
</tbody>
</table>
<ul>
<li><code>albert-base-v1</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 125M 参数量，在英文文本上进行训练而得到.</li>
<li><code>albert-base-v2</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 125M 参数量，在英文文本上进行训练而得到，相比 v1 使用了更多的数据量，花费更长的训练时间.</li>
</ul>
<hr>
<h4><span id="10-t5-及其变体"> 10 T5 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">t5-small</td>
<td style="text-align:center">6</td>
<td style="text-align:center">512</td>
<td style="text-align:center">8</td>
<td style="text-align:center">60M</td>
<td style="text-align:center">C4 语料</td>
</tr>
<tr>
<td style="text-align:center">t5-base</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">12</td>
<td style="text-align:center">220M</td>
<td style="text-align:center">C4 语料</td>
</tr>
<tr>
<td style="text-align:center">t5-large</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1024</td>
<td style="text-align:center">16</td>
<td style="text-align:center">770M</td>
<td style="text-align:center">C4 语料</td>
</tr>
</tbody>
</table>
<ul>
<li><code>t5-small</code> : 编码器具有 6 个隐层，输出 512 维张量，8 个自注意力头，共 60M 参数量，在 C4 语料上进行训练而得到.</li>
<li><code>t5-base</code> : 编码器具有 12 个隐层，输出 768 维张量，12 个自注意力头，共 220M 参数量，在 C4 语料上进行训练而得到.</li>
<li><code>t5-large</code> : 编码器具有 24 个隐层，输出 1024 维张量，16 个自注意力头，共 770M 参数量，在 C4 语料上进行训练而得到.</li>
</ul>
<hr>
<h4><span id="11-xlm-roberta-及其变体"> 11 XLM-RoBERTa 及其变体</span></h4>
<table>
<thead>
<tr>
<th style="text-align:center">模型名称</th>
<th style="text-align:center">隐层数</th>
<th style="text-align:center">张量维度</th>
<th style="text-align:center">自注意力头数</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">训练语料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">xlm-roberta-base</td>
<td style="text-align:center">12</td>
<td style="text-align:center">768</td>
<td style="text-align:center">8</td>
<td style="text-align:center">125M</td>
<td style="text-align:center">2.5TB 的 100 种语言文本</td>
</tr>
<tr>
<td style="text-align:center">xlm-roberta-large</td>
<td style="text-align:center">24</td>
<td style="text-align:center">1027</td>
<td style="text-align:center">16</td>
<td style="text-align:center">355M</td>
<td style="text-align:center">2.5TB 的 100 种语言文本</td>
</tr>
</tbody>
</table>
<ul>
<li><code>xlm-roberta-base</code> : 编码器具有 12 个隐层，输出 768 维张量，8 个自注意力头，共 125M 参数量，在 2.5TB 的 100 种语言文本上进行训练而得到.</li>
<li><code>xlm-roberta-large</code> : 编码器具有 24 个隐层，输出 1027 维张量，16 个自注意力头，共 355M 参数量，在 2.5TB 的 100 种语言文本上进行训练而得到.</li>
</ul>
<hr>
<p>预训练模型说明:</p>
<ul>
<li>所有上述预训练模型及其变体都是以 transformer 为基础，只是在模型结构如神经元连接方式，编码器隐层数，多头注意力的头数等发生改变，这些改变方式的大部分依据都是由在标准数据集上的表现而定，因此，对于我们使用者而言，不需要从理论上深度探究这些预训练模型的结构设计的优劣，只需要在自己处理的目标数据上，尽量遍历所有可用的模型对比得到最优效果即可.</li>
</ul>

            <div class="post-copyright">
    <div class="content">
        <p>最后更新： 2021年06月26日 10:41</p>
        <p>原始链接： <a class="post-url" href="/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/" title="NLP之常用预训练模型详解">https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/</a></p>
        <footer>
            <a href="https://leezhao415.github.io">
                <img src="/images/logo.jpg" alt="LeeZhao">
                LeeZhao
            </a>
        </footer>
    </div>
</div>

      
        
            
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;">赏</a>
</div>

<div id="reward" class="post-modal reward-lay">
    <a class="close" href="javascript:;" id="reward-close">×</a>
    <span class="reward-title">
        <i class="icon icon-quote-left"></i>
        请我吃糖~
        <i class="icon icon-quote-right"></i>
    </span>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechat_code.jpg" alt="打赏二维码">
        </div>
        <div class="reward-select">
            
            <label class="reward-select-item checked" data-id="wechat" data-wechat="/images/wechat_code.jpg">
                <img class="reward-select-item-wechat" src="/images/wechat.png" alt="微信">
            </label>
            
            
            <label class="reward-select-item" data-id="alipay" data-alipay="/images/alipay_code.jpg">
                <img class="reward-select-item-alipay" src="/images/alipay.png" alt="支付宝">
            </label>
            
        </div>
    </div>
</div>


        
    </div>
    <footer class="article-footer">
        
        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/&title=《NLP之常用预训练模型详解》 — 且听风吟，御剑于心！&pic=images/NLP预训练模型.jpeg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/&title=《NLP之常用预训练模型详解》 — 且听风吟，御剑于心！&source=" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《NLP之常用预训练模型详解》 — 且听风吟，御剑于心！&url=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/&via=https://leezhao415.github.io" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=https://leezhao415.github.io/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/" alt="微信分享二维码">
</div>

<div class="mask"></div>

        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/人工智能/" class="color5">人工智能</a>
      
    <a href="/tags/NLP/" class="color4">NLP</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link"><span class="post-toc-text"> NLP 中流行的预训练模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 1 BERT 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 2 GPT</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 3 GPT-2 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 4 Transformer-XL</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 5 XLNet 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 6 XLM</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 7 RoBERTa 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 8 DistilBERT 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 9 ALBERT</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 10 T5 及其变体</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link"><span class="post-toc-text"> 11 XLM-RoBERTa 及其变体</span></a></li></ol></li></ol>
        </nav>
    </aside>
    

<nav id="article-nav">
  
    <a href="/2021/06/24/NLP%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%BB%8Etransformer%E5%88%B0albert/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          NLP模型：从transformer到albert
        
      </span>
    </a>
  
  
    <a href="/2021/06/24/NLP%E4%B9%8B%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%A6%E8%A7%A3/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">NLP之常用数据集详解</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>



    
        <div id="SOHUCS" sid="NLP之常用预训练模型详解" ></div>
<script type="text/javascript">
    (function(){
        var appid = 'true';
        var conf = 'true';
        var width = window.innerWidth || document.documentElement.clientWidth;
        if (width < 960) {
            window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>
    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2024 LeeZhao<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
  var mihoConfig = {
      root: "https://leezhao415.github.io",
      animate: true,
      isHome: false,
      share: true,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/Hot/">Hot</a>
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/AIGC%E5%89%8D%E6%B2%BF/" style="font-size: 10px;">AIGC前沿</a> <a href="/tags/CV-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E7%AE%B1/" style="font-size: 10px;">CV/目标检测工具箱</a> <a href="/tags/CV%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 10px;">CV数据集</a> <a href="/tags/CV%E6%9C%AA%E6%9D%A5/" style="font-size: 10px;">CV未来</a> <a href="/tags/CV%E7%AE%97%E6%B3%95/" style="font-size: 10px;">CV算法</a> <a href="/tags/IOU/" style="font-size: 10px;">IOU</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MOT/" style="font-size: 10px;">MOT</a> <a href="/tags/NCNN%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">NCNN部署</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/NLP-BERT/" style="font-size: 10px;">NLP-BERT</a> <a href="/tags/NLP-%E5%8F%91%E5%B1%95%E5%8F%B2/" style="font-size: 10px;">NLP-发展史</a> <a href="/tags/NLP-%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" style="font-size: 10px;">NLP-模型优化</a> <a href="/tags/NLP-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%B7%A5%E5%85%B7/" style="font-size: 10px;">NLP/数据增强工具</a> <a href="/tags/NLP-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/" style="font-size: 10px;">NLP/评估指标</a> <a href="/tags/OpenCV%E4%B9%8BDNN%E6%A8%A1%E5%9D%97/" style="font-size: 10px;">OpenCV之DNN模块</a> <a href="/tags/PaddlePaddle/" style="font-size: 10px;">PaddlePaddle</a> <a href="/tags/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">Python数据分析</a> <a href="/tags/ReID/" style="font-size: 10px;">ReID</a> <a href="/tags/Transformer-DETR-CV/" style="font-size: 10px;">Transformer/DETR(CV)</a> <a href="/tags/VSLAM/" style="font-size: 11.67px;">VSLAM</a> <a href="/tags/YOLOX/" style="font-size: 10px;">YOLOX</a> <a href="/tags/YOLOX%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 11.67px;">YOLOX目标检测</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">三维建模</a> <a href="/tags/%E4%B8%94%E8%AF%BB%E6%96%87%E6%91%98/" style="font-size: 13.33px;">且读文摘</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 20px;">人工智能</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-CV/" style="font-size: 10px;">人工智能/CV</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 10px;">人脸识别</a> <a href="/tags/%E5%90%8D%E4%BA%BA%E5%90%8D%E8%A8%80/" style="font-size: 10px;">名人名言</a> <a href="/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">多任务学习模型</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 11.67px;">多模态</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">大数据框架</a> <a href="/tags/%E5%AF%92%E7%AA%91%E8%B5%8B/" style="font-size: 10px;">寒窑赋</a> <a href="/tags/%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">度量学习</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">操作系统</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 10px;">数据库原理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" style="font-size: 11.67px;">数据结构与算法</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 11.67px;">数据集</a> <a href="/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/" style="font-size: 10px;">智能家居</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 10px;">机器学习/损失函数</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E6%9B%B4%E6%96%B0/" style="font-size: 10px;">梯度更新</a> <a href="/tags/%E6%A6%82%E8%BF%B0/" style="font-size: 10px;">概述</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" style="font-size: 10px;">模型优化</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/" style="font-size: 10px;">模型性能指标</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" style="font-size: 16.67px;">模型部署</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">深度学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" style="font-size: 10px;">深度学习环境配置</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">深度模型</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89/" style="font-size: 10px;">深度模型（目标检测）</a> <a href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" style="font-size: 10px;">激活函数</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%EF%BC%89/" style="font-size: 10px;">目标检测（人脸检测）</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/" style="font-size: 10px;">目标跟踪</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" style="font-size: 10px;">知识蒸馏</a> <a href="/tags/%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE%E6%88%90%E6%9E%9C/" style="font-size: 10px;">科研项目成果</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 11.67px;">算法</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/" style="font-size: 18.33px;">编程工具</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" style="font-size: 10px;">编程语言</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">网络编程</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/" style="font-size: 10px;">网络通信</a> <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/" style="font-size: 10px;">自然语言处理NLP</a> <a href="/tags/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B/" style="font-size: 10px;">表面缺陷检测</a> <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" style="font-size: 10px;">视频理解</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 10px;">计算机视觉</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV/" style="font-size: 15px;">计算机视觉CV</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%BA%93/" style="font-size: 10px;">计算机视觉库</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%A1%B6%E4%BC%9A/" style="font-size: 10px;">计算机顶会</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a  href="/about">
                    <i class="fa fa-user"></i><span>About</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/AIGC%E5%89%8D%E6%B2%BF/" style="font-size: 10px;">AIGC前沿</a> <a href="/tags/CV-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E7%AE%B1/" style="font-size: 10px;">CV/目标检测工具箱</a> <a href="/tags/CV%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 10px;">CV数据集</a> <a href="/tags/CV%E6%9C%AA%E6%9D%A5/" style="font-size: 10px;">CV未来</a> <a href="/tags/CV%E7%AE%97%E6%B3%95/" style="font-size: 10px;">CV算法</a> <a href="/tags/IOU/" style="font-size: 10px;">IOU</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MOT/" style="font-size: 10px;">MOT</a> <a href="/tags/NCNN%E9%83%A8%E7%BD%B2/" style="font-size: 10px;">NCNN部署</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/NLP-BERT/" style="font-size: 10px;">NLP-BERT</a> <a href="/tags/NLP-%E5%8F%91%E5%B1%95%E5%8F%B2/" style="font-size: 10px;">NLP-发展史</a> <a href="/tags/NLP-%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" style="font-size: 10px;">NLP-模型优化</a> <a href="/tags/NLP-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%B7%A5%E5%85%B7/" style="font-size: 10px;">NLP/数据增强工具</a> <a href="/tags/NLP-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/" style="font-size: 10px;">NLP/评估指标</a> <a href="/tags/OpenCV%E4%B9%8BDNN%E6%A8%A1%E5%9D%97/" style="font-size: 10px;">OpenCV之DNN模块</a> <a href="/tags/PaddlePaddle/" style="font-size: 10px;">PaddlePaddle</a> <a href="/tags/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 10px;">Python数据分析</a> <a href="/tags/ReID/" style="font-size: 10px;">ReID</a> <a href="/tags/Transformer-DETR-CV/" style="font-size: 10px;">Transformer/DETR(CV)</a> <a href="/tags/VSLAM/" style="font-size: 11.67px;">VSLAM</a> <a href="/tags/YOLOX/" style="font-size: 10px;">YOLOX</a> <a href="/tags/YOLOX%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 11.67px;">YOLOX目标检测</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">三维建模</a> <a href="/tags/%E4%B8%94%E8%AF%BB%E6%96%87%E6%91%98/" style="font-size: 13.33px;">且读文摘</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 20px;">人工智能</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-CV/" style="font-size: 10px;">人工智能/CV</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" style="font-size: 10px;">人脸识别</a> <a href="/tags/%E5%90%8D%E4%BA%BA%E5%90%8D%E8%A8%80/" style="font-size: 10px;">名人名言</a> <a href="/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">多任务学习模型</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 11.67px;">多模态</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">大数据框架</a> <a href="/tags/%E5%AF%92%E7%AA%91%E8%B5%8B/" style="font-size: 10px;">寒窑赋</a> <a href="/tags/%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">度量学习</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">操作系统</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 10px;">数据库原理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" style="font-size: 11.67px;">数据结构与算法</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 11.67px;">数据集</a> <a href="/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/" style="font-size: 10px;">智能家居</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 10px;">机器学习/损失函数</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E6%9B%B4%E6%96%B0/" style="font-size: 10px;">梯度更新</a> <a href="/tags/%E6%A6%82%E8%BF%B0/" style="font-size: 10px;">概述</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/" style="font-size: 10px;">模型优化</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/" style="font-size: 10px;">模型性能指标</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" style="font-size: 16.67px;">模型部署</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">深度学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" style="font-size: 10px;">深度学习环境配置</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">深度模型</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89/" style="font-size: 10px;">深度模型（目标检测）</a> <a href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" style="font-size: 10px;">激活函数</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%EF%BC%89/" style="font-size: 10px;">目标检测（人脸检测）</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/" style="font-size: 10px;">目标跟踪</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/" style="font-size: 10px;">知识蒸馏</a> <a href="/tags/%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE%E6%88%90%E6%9E%9C/" style="font-size: 10px;">科研项目成果</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 11.67px;">算法</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/" style="font-size: 18.33px;">编程工具</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" style="font-size: 10px;">编程语言</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 10px;">网络编程</a> <a href="/tags/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/" style="font-size: 10px;">网络通信</a> <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86NLP/" style="font-size: 10px;">自然语言处理NLP</a> <a href="/tags/%E8%A1%A8%E9%9D%A2%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B/" style="font-size: 10px;">表面缺陷检测</a> <a href="/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" style="font-size: 10px;">视频理解</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 10px;">计算机视觉</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89CV/" style="font-size: 15px;">计算机视觉CV</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%BA%93/" style="font-size: 10px;">计算机视觉库</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%A1%B6%E4%BC%9A/" style="font-size: 10px;">计算机顶会</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>

<script src="/js/search.js"></script>


<script src="/js/main.js"></script>



  <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
  <div id="particles"></div>
  
<script src="/js/particles.js"></script>








  
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  <script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script>
  
<script src="/js/animate.js"></script>



  
<script src="/js/pop-img.js"></script>

  <script>
     $(".article-entry p img").popImg();
  </script>

  </div>
</body>
</html>